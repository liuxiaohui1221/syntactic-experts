# 优化方法汇总

## 1.分析MiduCTC模型预测能力
功能实现：将miduCTC模型预测正确和错误的样本进行保存对比，来判断模型大致对什么样的样本预测能力较弱。
比如可能存在：某类中文错误，或对某些实体，或某些语法结构等检测或纠错错误概率大。然后针对性的对某些类别错误进行数据扩增等。

## 2.模型集成（如：xgboost）
简单实现：pycorrector+MiduCTC双检错纠错，MiduCTC没有检测正确的样本继续使用pycorrector检测一遍，两者都判断正确才算正例，以提高检错率。

2021文本纠错比赛top1：

    1.top1报告：https://github.com/HillZhang1999/CTC-Report
    2.异构纠错模型集成：https://github.com/HillZhang1999/MuCGEC 中的模型融合策略参考./scorers/ChERRANT/ensemble.sh
## 3.句子中文表征增加词性
注：第一版本：将词性embedding通过和token embedding相加的方式训练有所下降，原因：可能破坏了原始预训练的表征能力。

注：第二版本：将词性embedding拼接到token embedding后面。

结论：在已训练的模型基础上继续训练2个epoch,提升0.7%后为0.3736，
比较不修改场景下继续训练2个epoch性能0.3698，说明引入词性只是稍微有效果。

注：第三个版本：在第二个版本基础上，和token类似，对词性取消初始的mask操作。

结论：训练2个epoch，性能下降至0.3626，故第三个版本的修改作废。故后续优化，使用第二个版本

注：第四个版本：在第二个版本基础上，引入拼音表征。

## 4.CTC模型和pycorrector模型在验证数据集表现分析优化
CTC模型缺点分析：

    1）有错误样本中，纠错不准确。
    替换错误，本为同音错误。比如”署假“实际为“暑假”，但预测为“春假”。  ---能同音替换符合语义的优先。其次才是不同音词替换。同音替换后使用腾讯词向量判断相似度，同音词替换扩增负例样本数
    替换错误，纠错地方不对。”节拍“本身正确，被预测为”节目“。         ---腾讯词向量进一步判断与句子相似度，融合拼音表征以一定程度限定跨拼音替换，让模型更关注同音替换问题
    
    2）有错误样本中，判为无错。多数有错被预测为无错：
    缺字补全问题：”无依靠“实际应为”无依无靠“。武装部 实际为：人民武装部。长夜漫 实际为：长夜漫漫  ---实体词库缺少，是否存在此类样本不足？扩增优化：实体词组类随机删除一个。
    同音替换问题：粮食欠收，实际为：粮食歉收。风光迤逦 实际为：风光旖旎   ---腾讯词向量进一步替换前后判断与句子相似度

    3）验证集预测结果样本统计：
        有错误样本预测统计：有错判为无错问题，纠错不准确问题
        [neg_predict_pos,neg_predict_other,idx]: 222,148,1014 
        [neg_predict_pos,neg_predict_other]比例: 0.22,0.15

        有错误样本中，判为无错的错误样本分布：缺字问题，同等替换问题，多字问题
        [缺失问题,同等替换问题,冗余问题,总数]: 31.00,184.00,7.00,222.00 
        [缺失问题,同等替换问题,冗余问题,总数]比例: 0.14,0.83,0.03 

        有错误样本中，纠错不对问题：
        [缺失问题,同等替换问题,冗余问题,总数]: 17,118,13,148 
        [缺失问题,同等替换问题,冗余问题,总数]比例: 0.11,0.80,0.09 
    结论分析：1.模型预测“有错判为无错”是“纠错不准确问题”的1.8倍。
            2.同等长度词或词组替换问题"为主要问题（同音替换或等长词组替换）占80%多
    无错样本分析：
        [无错判有错,无错数]：93 501
    4)extend数据集：
        有错误样本预测统计：
        [neg_predict_pos,neg_predict_other,idx]: 0,999,1000 
        [neg_predict_pos,neg_predict_other]比例: 0.00,1.00 
        有错误样本中，判为无错问题：
        [缺失问题,同等替换问题,冗余问题,总数]: 0.00,0.00,0.00,0.00 
        有错误样本中，纠错不对问题：
        [缺失问题,同等替换问题,冗余问题,总数]: 200,599,200,999 
        [缺失问题,同等替换问题,冗余问题,总数]比例: 0.20,0.60,0.20 
    结论分析：全部是错误样本的纠错不准确问题，其中同等替换问题占多数。
pycorrector缺点：

    实体词组不足，比如地名被误认；分词不准确导致纠错问题
优化点：

    1.CTC判正，pycorrector判错的样本，根据pycorrector纠错词替换(满足任意一个替换即可)后，
    再次通过CTC语义判断，若也为正，则将样本标记为错例，按pycorrector方式处理。注意：排除误检，即不考虑pycor检测的词语在原文分别前后组成词语。
    
    2.CTC判错加“的”的可以忽略，在“已”后加“经”字的可以忽略
    
    3.首先对实体进行检测，对待替换词为实体的忽略。----优化pycorrector
    
    4.训练集或验证集中的假负例筛选：1.source和target相等但为negative的，或不等为positive的（继续分析可能为两正例？）--->手动修改并重新训练
    
    注：已分析修改了验证集中3个错误标注样本
    
    5.词向量换成腾讯中文预训练词向量效果验证（表征能力，注：估计不行，换成如下实现）
    腾讯词向量：http://www.wjhsh.net/yanqiang-p-13536619.html
    
    简单实现：将纠错前的词组合纠错后的词组分别和句子（不包含该词组）进行相似度判断，谁更靠近？若替换后的词更靠近则确认该纠错词。

#### 验证集文本长度统计大于128的样本数：
exceed,total nums: 55 1014

优化方法：训练时embedding设置128，则对于文本长度128的截取方案进行判断：
首先默认对文本按逗号分隔，分别比较两头与标签是否相等，若其中一头相等则对这头进行截断。
## 5.常用语法错误检测模板

## 6.数据集扩增中得到音似和形似汉字进行替换
简单实现：70%音似，20%形似，10%随机

汉字混淆集构建（用于数据扩增以及辅助纠错）：
有学者对4100个错误的汉字的研究统计，发现76%的错误与正确字符和错误字符之间的语音相似性有关，46%是由于视觉相似性，29%涉及两个因素。
## 7.引入Seq2Seq模型
实现方案：

    1.结合StructBert对乱序纠错的优势，MacBert等。
    2.训练一个基于训练模型从拼音序列翻译到中文序列的模型，目的使得模型学习同音文本纠错问题以及整个句子的语义。
